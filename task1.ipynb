{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73270376",
   "metadata": {},
   "source": [
    "# Case 1 - Discover the Pattern of Success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3b4b5",
   "metadata": {},
   "source": [
    "## A. Import Library & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b490d965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheets in 'Study Case DA.xlsx': ['Talent Variable (TV) & Talent G', 'dim_companies', 'dim_areas', 'dim_positions', 'dim_departments', 'dim_divisions', 'dim_directorates', 'dim_grades', 'dim_education', 'dim_majors', 'dim_competency_pillars', 'employees', 'profiles_psych', 'papi_scores', 'strengths', 'performance_yearly', 'competencies_yearly']\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "DB_FILE = 'employee_data.duckdb'\n",
    "EXCEL_FILE = 'Study Case DA.xlsx'\n",
    "\n",
    "wb = load_workbook(EXCEL_FILE, read_only=True)\n",
    "sheet_names = wb.sheetnames\n",
    "print(f\"Sheets in '{EXCEL_FILE}': {sheet_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2616e0",
   "metadata": {},
   "source": [
    "## B. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d815ec",
   "metadata": {},
   "source": [
    "### 1. Use SQL script and prepare some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "958ae8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_SCHEMA_SCRIPT = '''\n",
    "-- Dimension Tables\n",
    "CREATE TABLE dim_companies (\n",
    "  company_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_areas (\n",
    "  area_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_positions (\n",
    "  position_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_departments (\n",
    "  department_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_divisions (\n",
    "  division_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_directorates (\n",
    "  directorate_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_grades (\n",
    "  grade_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_education (\n",
    "  education_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_majors (\n",
    "  major_id BIGINT PRIMARY KEY,\n",
    "  name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE dim_competency_pillars (\n",
    "  pillar_code VARCHAR(3) PRIMARY KEY,\n",
    "  pillar_label TEXT NOT NULL\n",
    ");\n",
    "\n",
    "-- Fact & Profile Tables\n",
    "CREATE TABLE employees (\n",
    "  employee_id TEXT PRIMARY KEY,\n",
    "  fullname TEXT,\n",
    "  nip TEXT,\n",
    "  company_id BIGINT REFERENCES dim_companies(company_id),\n",
    "  area_id BIGINT REFERENCES dim_areas(area_id),\n",
    "  position_id BIGINT REFERENCES dim_positions(position_id),\n",
    "  department_id BIGINT REFERENCES dim_departments(department_id),\n",
    "  division_id BIGINT REFERENCES dim_divisions(division_id),\n",
    "  directorate_id BIGINT REFERENCES dim_directorates(directorate_id),\n",
    "  grade_id BIGINT REFERENCES dim_grades(grade_id),\n",
    "  education_id BIGINT REFERENCES dim_education(education_id),\n",
    "  major_id BIGINT REFERENCES dim_majors(major_id),\n",
    "  years_of_service_months BIGINT\n",
    ");\n",
    "\n",
    "CREATE TABLE profiles_psych (\n",
    "  employee_id TEXT PRIMARY KEY REFERENCES employees(employee_id),\n",
    "  pauli NUMERIC,\n",
    "  faxtor NUMERIC,\n",
    "  disc TEXT,\n",
    "  disc_word TEXT,\n",
    "  mbti TEXT,\n",
    "  iq NUMERIC,\n",
    "  gtq INT,\n",
    "  tiki INT\n",
    ");\n",
    "\n",
    "CREATE TABLE papi_scores (\n",
    "  employee_id TEXT REFERENCES employees(employee_id),\n",
    "  scale_code TEXT,\n",
    "  score INT,\n",
    "  PRIMARY KEY (employee_id, scale_code)\n",
    ");\n",
    "\n",
    "CREATE TABLE strengths (\n",
    "  employee_id TEXT REFERENCES employees(employee_id),\n",
    "  rank INT,\n",
    "  theme TEXT,\n",
    "  PRIMARY KEY (employee_id, rank)\n",
    ");\n",
    "\n",
    "CREATE TABLE performance_yearly (\n",
    "  employee_id TEXT REFERENCES employees(employee_id),\n",
    "  year INT,\n",
    "  rating INT,\n",
    "  PRIMARY KEY (employee_id, year)\n",
    ");\n",
    "\n",
    "CREATE TABLE competencies_yearly (\n",
    "  employee_id TEXT REFERENCES employees(employee_id),\n",
    "  pillar_code VARCHAR(3) REFERENCES dim_competency_pillars(pillar_code),\n",
    "  year INT,\n",
    "  score INT,\n",
    "  PRIMARY KEY (employee_id, pillar_code, year)\n",
    ");\n",
    "\n",
    "-- Indexes (Non-Primary Key)\n",
    "CREATE INDEX performance_yearly_index_3 ON performance_yearly (year);\n",
    "CREATE INDEX competencies_yearly_index_5 ON competencies_yearly (pillar_code, year);\n",
    "\n",
    "-- Comments\n",
    "COMMENT ON TABLE dim_competency_pillars IS 'Codes: GDR, CEX, IDS, QDD, STO, SEA, VCU, LIE, FTC, CSI';\n",
    "COMMENT ON TABLE strengths IS 'CliftonStrengths rank 1..14';\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0067c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for data processing (table names, primary key variable, and string variable)\n",
    "TABLE_NAMES = [\n",
    "    'dim_companies',\n",
    "    'dim_areas',\n",
    "    'dim_positions',\n",
    "    'dim_departments',\n",
    "    'dim_divisions',\n",
    "    'dim_directorates',\n",
    "    'dim_grades',\n",
    "    'dim_education',\n",
    "    'dim_majors',\n",
    "    'dim_competency_pillars',\n",
    "    'employees',\n",
    "    'profiles_psych',\n",
    "    'papi_scores',\n",
    "    'strengths',\n",
    "    'performance_yearly',\n",
    "    'competencies_yearly'\n",
    "]\n",
    "\n",
    "PK_COLUMNS = {\n",
    "    'employees': ['employee_id'],\n",
    "    'profiles_psych': ['employee_id'],\n",
    "    'dim_competency_pillars': ['pillar_code'],\n",
    "    'papi_scores': ['employee_id', 'scale_code'],\n",
    "    'strengths': ['employee_id', 'rank'],\n",
    "    'performance_yearly': ['employee_id', 'year'],\n",
    "    'competencies_yearly': ['employee_id', 'pillar_code', 'year']\n",
    "}\n",
    "\n",
    "DTYPE_OVERRIDES = {\n",
    "    'employees': {'employee_id': str, 'nip': str},\n",
    "    'profiles_psych': {'employee_id': str},\n",
    "    'papi_scores': {'employee_id': str, 'scale_code': str},\n",
    "    'strengths': {'employee_id': str},\n",
    "    'performance_yearly': {'employee_id': str},\n",
    "    'competencies_yearly': {'employee_id': str, 'pillar_code': str},\n",
    "    'dim_competency_pillars': {'pillar_code': str}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cd589",
   "metadata": {},
   "source": [
    "### 2. Define function for data extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183aa7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema(conn):\n",
    "    \"\"\"Executes the main SQL script to create all tables.\"\"\"\n",
    "    try:\n",
    "        print(\"Connecting to database and creating schema...\")\n",
    "        conn.execute(SQL_SCHEMA_SCRIPT)\n",
    "        print(\"Schema created successfully.\")\n",
    "    except duckdb.Error as e:\n",
    "        print(f\"Error creating schema: {e}\")\n",
    "        print(\"The database might already exist. If so, delete the file '{DB_FILE}' and try again.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def load_data_from_excel(conn):\n",
    "    \"\"\"Loops through table names, reading from Excel sheets and inserting into DuckDB.\"\"\"\n",
    "    print(f\"\\nStarting data load from '{EXCEL_FILE}'...\")\n",
    "    \n",
    "    for table_name in TABLE_NAMES:\n",
    "        print(f\"  - Loading data for table: '{table_name}'\")\n",
    "        try:\n",
    "            # Get specific dtypes for this table\n",
    "            dtypes = DTYPE_OVERRIDES.get(table_name, None)\n",
    "            \n",
    "            # Read the corresponding sheet from the Excel file\n",
    "            df = pd.read_excel(EXCEL_FILE, sheet_name=table_name, engine='openpyxl', dtype=dtypes)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(f\"    ...Sheet '{table_name}' is empty. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Handle NULLs in Primary Key columns\n",
    "            if table_name in PK_COLUMNS:\n",
    "                pk_cols = PK_COLUMNS[table_name]\n",
    "                initial_rows = len(df)\n",
    "                # Drop rows where any of the PK columns are null\n",
    "                df.dropna(subset=pk_cols, inplace=True)\n",
    "                dropped_rows = initial_rows - len(df)\n",
    "                if dropped_rows > 0:\n",
    "                    print(f\"    ...Dropped {dropped_rows} rows with NULL values in primary key columns: {pk_cols}\")\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"    ...No valid data left after cleaning. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Register the DataFrame as a temporary view in DuckDB\n",
    "            conn.register('temp_table', df)\n",
    "            \n",
    "            # Use INSERT BY NAME\n",
    "            # This maps columns by name instead of by position.\n",
    "            conn.execute(f\"INSERT INTO {table_name} BY NAME SELECT * FROM temp_table\")\n",
    "            \n",
    "            # Clean up the temporary view\n",
    "            conn.unregister('temp_table')\n",
    "            \n",
    "            print(f\"    ...Success: Loaded {len(df)} rows into '{table_name}'.\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file '{EXCEL_FILE}' was not found.\")\n",
    "            sys.exit(1)\n",
    "        except Exception as e:\n",
    "            # This often happens if the sheet doesn't exist\n",
    "            print(f\"    ...Error loading sheet '{table_name}': {e}\")\n",
    "            print(\"    ...Skipping this table. Please check your Excel file.\")\n",
    "\n",
    "def verify_data(conn):\n",
    "    \"\"\"Runs a few simple queries to confirm data was loaded.\"\"\"\n",
    "    print(\"\\nVerifying data load...\")\n",
    "    try:\n",
    "        # Check employee count\n",
    "        employee_count = conn.execute(\"SELECT COUNT(*) FROM employees\").fetchone()[0]\n",
    "        print(f\"Total employees loaded: {employee_count}\")\n",
    "        \n",
    "        # Check company count\n",
    "        company_count = conn.execute(\"SELECT COUNT(*) FROM dim_companies\").fetchone()[0]\n",
    "        print(f\"Total companies loaded: {company_count}\")\n",
    "        \n",
    "        # Sample data from employees\n",
    "        print(\"\\nSample 5 employees:\")\n",
    "        print(conn.execute(\"SELECT employee_id, fullname, nip FROM employees LIMIT 5\").df())\n",
    "        \n",
    "        # Sample data from performance\n",
    "        print(\"\\nSample 5 performance records:\")\n",
    "        print(conn.execute(\"SELECT * FROM performance_yearly LIMIT 5\").df())\n",
    "        \n",
    "    except duckdb.Error as e:\n",
    "        print(f\"Error during verification: {e}\")\n",
    "        print(\"Verification failed. Data may be incomplete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da6f2c",
   "metadata": {},
   "source": [
    "### 3. Use function to extracting data from sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dd0b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee_data.duckdb deleted successfully.\n",
      "Connecting to database and creating schema...\n",
      "Schema created successfully.\n",
      "\n",
      "Starting data load from 'Study Case DA.xlsx'...\n",
      "  - Loading data for table: 'dim_companies'\n",
      "    ...Success: Loaded 4 rows into 'dim_companies'.\n",
      "  - Loading data for table: 'dim_areas'\n",
      "    ...Success: Loaded 4 rows into 'dim_areas'.\n",
      "  - Loading data for table: 'dim_positions'\n",
      "    ...Success: Loaded 6 rows into 'dim_positions'.\n",
      "  - Loading data for table: 'dim_departments'\n",
      "    ...Success: Loaded 6 rows into 'dim_departments'.\n",
      "  - Loading data for table: 'dim_divisions'\n",
      "    ...Success: Loaded 5 rows into 'dim_divisions'.\n",
      "  - Loading data for table: 'dim_directorates'\n",
      "    ...Success: Loaded 3 rows into 'dim_directorates'.\n",
      "  - Loading data for table: 'dim_grades'\n",
      "    ...Success: Loaded 3 rows into 'dim_grades'.\n",
      "  - Loading data for table: 'dim_education'\n",
      "    ...Success: Loaded 4 rows into 'dim_education'.\n",
      "  - Loading data for table: 'dim_majors'\n",
      "    ...Success: Loaded 6 rows into 'dim_majors'.\n",
      "  - Loading data for table: 'dim_competency_pillars'\n",
      "    ...Success: Loaded 10 rows into 'dim_competency_pillars'.\n",
      "  - Loading data for table: 'employees'\n",
      "    ...Success: Loaded 2010 rows into 'employees'.\n",
      "  - Loading data for table: 'profiles_psych'\n",
      "    ...Success: Loaded 2010 rows into 'profiles_psych'.\n",
      "  - Loading data for table: 'papi_scores'\n",
      "    ...Success: Loaded 40200 rows into 'papi_scores'.\n",
      "  - Loading data for table: 'strengths'\n",
      "    ...Success: Loaded 28140 rows into 'strengths'.\n",
      "  - Loading data for table: 'performance_yearly'\n",
      "    ...Success: Loaded 10050 rows into 'performance_yearly'.\n",
      "  - Loading data for table: 'competencies_yearly'\n",
      "    ...Success: Loaded 100500 rows into 'competencies_yearly'.\n",
      "\n",
      "Verifying data load...\n",
      "Total employees loaded: 2010\n",
      "Total companies loaded: 4\n",
      "\n",
      "Sample 5 employees:\n",
      "  employee_id                  fullname     nip\n",
      "0   EMP100000            Rendra Pratama  806137\n",
      "1   EMP100001            Wulan Setiawan  476388\n",
      "2   EMP100002  Julia Jatmiko Situmorang  941921\n",
      "3   EMP100003                 Oka Halim  751615\n",
      "4   EMP100004               Dwi Pratama  443809\n",
      "\n",
      "Sample 5 performance records:\n",
      "  employee_id  year  rating\n",
      "0   EMP100000  2021       2\n",
      "1   EMP100001  2021    <NA>\n",
      "2   EMP100002  2021       2\n",
      "3   EMP100003  2021    <NA>\n",
      "4   EMP100004  2021       3\n",
      "\n",
      "All done! Your database is saved as 'employee_data.duckdb'.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(DB_FILE):\n",
    "    os.remove(DB_FILE)\n",
    "    print(f\"{DB_FILE} deleted successfully.\")\n",
    "else:\n",
    "    print(f\"{DB_FILE} does not exist.\")\n",
    "\n",
    "with duckdb.connect(database=DB_FILE, read_only=False) as conn:\n",
    "    create_schema(conn)\n",
    "    load_data_from_excel(conn)\n",
    "    verify_data(conn)\n",
    "\n",
    "print(f\"\\nAll done! Your database is saved as '{DB_FILE}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89344ad2",
   "metadata": {},
   "source": [
    "## C. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c7c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
